{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed50e0bd-38d8-4e52-a362-13b79c99321f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-07 23:49:55,963] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Warning: The default cache directory for DeepSpeed Triton autotune, /home/jovyan/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Training Epoch 1/10 Batch Size: 8: 100%|██████████| 20/20 [00:01<00:00, 13.16it/s, Training Loss=0.538]\n",
      "Validation Epoch 1/10: 100%|██████████| 6/6 [00:00<00:00, 53.16it/s, Validation Loss=0.237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Validation Loss: 0.3569177861015002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10 Batch Size: 8: 100%|██████████| 20/20 [00:01<00:00, 18.54it/s, Training Loss=0.315]\n",
      "Validation Epoch 2/10: 100%|██████████| 6/6 [00:00<00:00, 57.35it/s, Validation Loss=0.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Validation Loss: 0.24269748975833258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10 Batch Size: 8: 100%|██████████| 20/20 [00:01<00:00, 17.53it/s, Training Loss=0.176]\n",
      "Validation Epoch 3/10: 100%|██████████| 6/6 [00:00<00:00, 53.51it/s, Validation Loss=0.144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Validation Loss: 0.2240831802288691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10 Batch Size: 8: 100%|██████████| 20/20 [00:01<00:00, 19.04it/s, Training Loss=0.213]\n",
      "Validation Epoch 4/10: 100%|██████████| 6/6 [00:00<00:00, 62.85it/s, Validation Loss=0.139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Validation Loss: 0.20492582519849142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10 Batch Size: 8: 100%|██████████| 20/20 [00:01<00:00, 19.39it/s, Training Loss=0.118]\n",
      "Validation Epoch 5/10: 100%|██████████| 6/6 [00:00<00:00, 55.71it/s, Validation Loss=0.103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Validation Loss: 0.19419589390357336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10 Batch Size: 8: 100%|██████████| 20/20 [00:01<00:00, 19.20it/s, Training Loss=0.256]\n",
      "Validation Epoch 6/10: 100%|██████████| 6/6 [00:00<00:00, 62.02it/s, Validation Loss=0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Validation Loss: 0.20991607010364532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10 Batch Size: 8: 100%|██████████| 20/20 [00:01<00:00, 19.31it/s, Training Loss=0.136] \n",
      "Validation Epoch 7/10: 100%|██████████| 6/6 [00:00<00:00, 63.33it/s, Validation Loss=0.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Validation Loss: 0.19418700287739435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10 Batch Size: 8: 100%|██████████| 20/20 [00:01<00:00, 19.02it/s, Training Loss=0.102] \n",
      "Validation Epoch 8/10: 100%|██████████| 6/6 [00:00<00:00, 60.65it/s, Validation Loss=0.114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Validation Loss: 0.20586994414528212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10 Batch Size: 8: 100%|██████████| 20/20 [00:01<00:00, 18.37it/s, Training Loss=0.101] \n",
      "Validation Epoch 9/10: 100%|██████████| 6/6 [00:00<00:00, 51.78it/s, Validation Loss=0.143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Validation Loss: 0.21140062560637793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10 Batch Size: 8: 100%|██████████| 20/20 [00:01<00:00, 19.11it/s, Training Loss=0.138] \n",
      "Validation Epoch 10/10: 100%|██████████| 6/6 [00:00<00:00, 60.70it/s, Validation Loss=0.184]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Validation Loss: 0.21557331085205078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Install necessary dependencies\n",
    "!pip -q install accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7 torch torchtext sentencepiece pandas tqdm datasets\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Load dataset\n",
    "# data_sample = load_dataset(\"Leonardorm7/PP\")\n",
    "data_sample = load_dataset(\"Leonardorm7/PPAPI\")\n",
    "\n",
    "# Update dataset structure\n",
    "updated_data = [{'Input': item['Input'], 'Python code': item['Python code']} for item in data_sample['train']]\n",
    "df = pd.DataFrame(updated_data)\n",
    "\n",
    "# Define device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Prepare tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('distilgpt2').to(device)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Dataset class\n",
    "class LanguageDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.data = df.to_dict(orient='records')\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]['Input']\n",
    "        y = self.data[idx]['Python code']\n",
    "        text = f\"{x} | {y}\"\n",
    "        tokens = self.tokenizer.encode_plus(text, return_tensors='pt', max_length=128, padding='max_length', truncation=True)\n",
    "        return tokens\n",
    "\n",
    "# Prepare dataset\n",
    "data_sample = LanguageDataset(df, tokenizer)\n",
    "train_size = int(0.8 * len(data_sample))\n",
    "valid_size = len(data_sample) - train_size\n",
    "train_data, valid_data = random_split(data_sample, [train_size, valid_size])\n",
    "\n",
    "# Create loaders\n",
    "BATCH_SIZE = 8\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Training configuration\n",
    "num_epochs = 10\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# DataFrame for results\n",
    "results = pd.DataFrame(columns=['epoch', 'transformer', 'batch_size', 'gpu', 'training_loss', 'validation_loss', 'epoch_duration_sec'])\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    epoch_training_loss = 0\n",
    "    train_iterator = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs} Batch Size: {BATCH_SIZE}\")\n",
    "    for batch in train_iterator:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = batch['input_ids'].squeeze(1).to(device)\n",
    "        outputs = model(input_ids=inputs, labels=inputs)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_iterator.set_postfix({'Training Loss': loss.item()})\n",
    "        epoch_training_loss += loss.item()\n",
    "    avg_epoch_training_loss = epoch_training_loss / len(train_iterator)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    epoch_validation_loss = 0\n",
    "    valid_iterator = tqdm(valid_loader, desc=f\"Validation Epoch {epoch+1}/{num_epochs}\")\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_iterator:\n",
    "            inputs = batch['input_ids'].squeeze(1).to(device)\n",
    "            outputs = model(input_ids=inputs, labels=inputs)\n",
    "            loss = outputs.loss\n",
    "            valid_iterator.set_postfix({'Validation Loss': loss.item()})\n",
    "            epoch_validation_loss += loss.item()\n",
    "    avg_epoch_validation_loss = epoch_validation_loss / len(valid_iterator)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_duration_sec = end_time - start_time\n",
    "\n",
    "    new_row = {\n",
    "        'epoch': epoch+1,\n",
    "        'transformer': 'distilgpt2',\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'gpu': 0,\n",
    "        'training_loss': avg_epoch_training_loss,\n",
    "        'validation_loss': avg_epoch_validation_loss,\n",
    "        'epoch_duration_sec': epoch_duration_sec\n",
    "    }\n",
    "    results.loc[len(results)] = new_row\n",
    "    print(f\"Epoch: {epoch+1}, Validation Loss: {avg_epoch_validation_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d13cac8-a3f0-4c51-889c-8ff533341fb8",
   "metadata": {},
   "source": [
    "# Trained model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7043d71b-c557-4941-afb5-19de6c5b0756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a 5-slide presentation with yellow background, each slide with Slide Title in Calibri size 45 and a bullet list containing four points in Calibri size 20 | api.create_presentation('Yellow Slides')\n",
      "titles = [\"Slide 1\", \"Slide 2\", \"Slide 3\",                                              else: if i %(layout='title and content')\n",
      "for i in range(5):\n",
      "api.change_bullet_points(4):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_str=\"Create a 5-slide presentation with yellow background, each slide with Slide Title in Calibri size 45 and a bullet list containing four points in Calibri size 20\"\n",
    "input_ids = tokenizer.encode(input_str, return_tensors='pt').to(device)\n",
    "output = model.generate(input_ids, max_length=3024, num_return_sequences=1, do_sample=True, top_k=8, top_p=0.95, temperature=0.5, repetition_penalty=1.2, pad_token_id=tokenizer.eos_token_id)\n",
    "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ca75db-4ca0-4631-9b80-9f20a6aea58c",
   "metadata": {},
   "source": [
    "# Few shot Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82410750-8f6d-44e4-be08-cb148bf11b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of input_ids: 766\n",
      "Below are some examples of how to create presentations:\n",
      "\n",
      "### Instruction:\n",
      "Create a 4 slide presentation with light green background, each slide with Slide Title in Times New Roman size 40 and a bullet list containing two points in Times New Roman size 30\n",
      "### Response:\n",
      "\n",
      "api.create_presentation('Light Green Slides')\n",
      "titles = [\"Slide 1\", \"Slide 2\", \"Slide 3\", \"Slide 4\"]\n",
      "bullet_points = [\n",
      "    [\"Point 1\", \"Point 2\"],\n",
      "    [\"Item A\", \"Item B\"],\n",
      "    [\"Fact 1\", \"Fact 2\"],\n",
      "    [\"Detail X\", \"Detail Y\"]\n",
      "]\n",
      "for i in range(4):\n",
      "    api.add_slide(layout='title and content')\n",
      "    api.change_background_color(i + 1, (144, 238, 144))\n",
      "    api.add_text_to_slide(i + 1, titles[i], placeholder=0)\n",
      "    for point in bullet_points[i]:\n",
      "        api.add_bullet_point(i + 1, point)\n",
      "    api.change_font(i + 1, 0, 'Times New Roman')\n",
      "    api.change_font_size(i + 1, 0, 40)\n",
      "    api.change_font(i + 1, 1, 'Times New Roman')\n",
      "    api.change_font_size(i + 1, 1, 30)\n",
      "api.save_presentation('light_green_slides.pptx')\n",
      "        \n",
      "\n",
      "### Instruction:\n",
      "Create a 3 slide presentation with blue background, each slide with Slide Title in Arial size 35 and a bullet list containing three points in Arial size 25\n",
      "### Response:\n",
      "\n",
      "api.create_presentation('Blue Slides')\n",
      "titles = [\"Slide 1\", \"Slide 2\", \"Slide 3\"]\n",
      "bullet_points = [\n",
      "    [\"Point A\", \"Point B\", \"Point C\"],\n",
      "    [\"Item 1\", \"Item 2\", \"Item 3\"],\n",
      "    [\"Detail X\", \"Detail Y\", \"Detail Z\"]\n",
      "]\n",
      "for i in range(3):\n",
      "    api.add_slide(layout='title and content')\n",
      "    api.change_background_color(i + 1, (0, 0, 255))\n",
      "    api.add_text_to_slide(i + 1, titles[i], placeholder=0)\n",
      "    for point in bullet_points[i]:\n",
      "        api.add_bullet_point(i + 1, point)\n",
      "    api.change_font(i + 1, 0, 'Arial')\n",
      "    api.change_font_size(i + 1, 0, 35)\n",
      "    api.change_font(i + 1, 1, 'Arial')\n",
      "    api.change_font_size(i + 1, 1, 25)\n",
      "api.save_presentation('blue_slides.pptx')\n",
      "        \n",
      "\n",
      "### Instruction:\n",
      "Create a 5-slide presentation with yellow background, each slide with Slide Title in Calibri size 45 and a bullet list containing four points in Calibri size 20\n",
      "### Response:\n",
      "\n",
      "Create a 5-slide presentation with yellow background, each slide with Slide Title in Calibri size 45 and a bullet list containing four points in Calibri size 20 | api.create_presentation('Yellow Slides')\n",
      "\n",
      "titles = [\"Slide 1 Title\", \"Slide 2 Title\", \"Slide 3 Title\", \"Slide 4 Title\", \"Slide 5 Title\"]\n",
      "bullet_points = [\n",
      "    [\"Point 1\", \"Point 2\", \"Point 3\", \"Point 4\", \"Point 5\"],\n",
      "    [\"Item A\", \"Item B\", \"Item C\", \"Item D\"],\n",
      "    [\"Fact 1\", \"Fact 2\", \"Fact 3\", \"Fact 4\", \"Fact 5\"]\n",
      "]\n",
      "\n",
      "for i in range(5):\n",
      "\n",
      "for i in range(6):\n",
      "     [\"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X]\n",
      "       [\"Detail X\", \"Detail X\"],\n",
      "        [\"Detail X       [\"Detail X            [\"Detail X\", \"Detail X                                                                                                          [\"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X           [\"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\", \"Detail X\"]\n",
      "       [\"Detail X\", \"Detail X\", \"Detail X\"]\n",
      "]\n",
      "for i else\n",
      "for i else\n",
      "for i else:\n",
      "     else:\n",
      "    else:\n",
      "   else:\n",
      "   else:\n",
      "   else else:\n",
      "  else else:\n",
      "  else else else:\n",
      "  else else:\n",
      "  else else:\n",
      "  else else:\n",
      "  else else:\n",
      "  else else:\n",
      "  else else:\n",
      "  else:\n",
      "  else else:\n",
      "  else:\n",
      "  else else:\n",
      "  else:\n",
      "  else else:\n",
      "  else:\n",
      "  else:\n",
      "  else else:\n",
      "  else:\n",
      "  else:\n",
      "  else:\n",
      "  else:\n",
      "  else:\n",
      "  else:\n",
      "  else:\n",
      "  else:\n",
      "  else:\n",
      "  else:\n",
      "  else:\n",
      "  else:\n",
      "  else:\n",
      "  else:\n",
      "  else else:\n",
      "  else:\n",
      "  else:\n",
      "  else else:\n",
      "  else:\n",
      "  else else:\n",
      "  else:\n",
      "  else else:\n",
      "  else\n",
      "  else:\n",
      "  else else\n",
      "  else:\n",
      "  else else\n",
      "  else:\n",
      "  else else\n",
      "  else else else\n",
      "  else else else\n",
      "   else:\n",
      "  else else\n",
      "  else else else else\n",
      "   else else   else\n",
      "  else  else  else  else  else  else  else else  else\n",
      "  else else else else else\n",
      "  else else else\n"
     ]
    }
   ],
   "source": [
    "\n",
    "few_shot_examples = [\n",
    "    {\n",
    "        \"instruction\": \"Create a 4 slide presentation with light green background, each slide with Slide Title in Times New Roman size 40 and a bullet list containing two points in Times New Roman size 30\",\n",
    "        \"response\": \"\"\"\n",
    "api.create_presentation('Light Green Slides')\n",
    "titles = [\"Slide 1\", \"Slide 2\", \"Slide 3\", \"Slide 4\"]\n",
    "bullet_points = [\n",
    "    [\"Point 1\", \"Point 2\"],\n",
    "    [\"Item A\", \"Item B\"],\n",
    "    [\"Fact 1\", \"Fact 2\"],\n",
    "    [\"Detail X\", \"Detail Y\"]\n",
    "]\n",
    "for i in range(4):\n",
    "    api.add_slide(layout='title and content')\n",
    "    api.change_background_color(i + 1, (144, 238, 144))\n",
    "    api.add_text_to_slide(i + 1, titles[i], placeholder=0)\n",
    "    for point in bullet_points[i]:\n",
    "        api.add_bullet_point(i + 1, point)\n",
    "    api.change_font(i + 1, 0, 'Times New Roman')\n",
    "    api.change_font_size(i + 1, 0, 40)\n",
    "    api.change_font(i + 1, 1, 'Times New Roman')\n",
    "    api.change_font_size(i + 1, 1, 30)\n",
    "api.save_presentation('light_green_slides.pptx')\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Create a 3 slide presentation with blue background, each slide with Slide Title in Arial size 35 and a bullet list containing three points in Arial size 25\",\n",
    "        \"response\": \"\"\"\n",
    "api.create_presentation('Blue Slides')\n",
    "titles = [\"Slide 1\", \"Slide 2\", \"Slide 3\"]\n",
    "bullet_points = [\n",
    "    [\"Point A\", \"Point B\", \"Point C\"],\n",
    "    [\"Item 1\", \"Item 2\", \"Item 3\"],\n",
    "    [\"Detail X\", \"Detail Y\", \"Detail Z\"]\n",
    "]\n",
    "for i in range(3):\n",
    "    api.add_slide(layout='title and content')\n",
    "    api.change_background_color(i + 1, (0, 0, 255))\n",
    "    api.add_text_to_slide(i + 1, titles[i], placeholder=0)\n",
    "    for point in bullet_points[i]:\n",
    "        api.add_bullet_point(i + 1, point)\n",
    "    api.change_font(i + 1, 0, 'Arial')\n",
    "    api.change_font_size(i + 1, 0, 35)\n",
    "    api.change_font(i + 1, 1, 'Arial')\n",
    "    api.change_font_size(i + 1, 1, 25)\n",
    "api.save_presentation('blue_slides.pptx')\n",
    "        \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Función para crear el prompt few-shot\n",
    "def create_few_shot_prompt(instruction, examples):\n",
    "    prompt = \"Below are some examples of how to create presentations:\\n\\n\"\n",
    "    for example in examples:\n",
    "        prompt += f\"### Instruction:\\n{example['instruction']}\\n### Response:\\n{example['response']}\\n\\n\"\n",
    "    prompt += \"### Instruction:\\n\" + instruction + \"\\n### Response:\\n\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "input_str=\"Create a 5-slide presentation with yellow background, each slide with Slide Title in Calibri size 45 and a bullet list containing four points in Calibri size 20\"\n",
    "\n",
    "few_shot_prompt = create_few_shot_prompt(input_str, few_shot_examples)\n",
    "\n",
    "input_ids = tokenizer.encode(few_shot_prompt, return_tensors='pt').to(device)\n",
    "\n",
    "# To reduce the number of examples\n",
    "few_shot_examples = [few_shot_examples[0]]  # to use only the first example\n",
    "\n",
    "output = model.generate(\n",
    "    input_ids, \n",
    "    max_length=4096,  \n",
    "    num_return_sequences=1, \n",
    "    do_sample=True, \n",
    "    top_k=50,  \n",
    "    top_p=0.95, \n",
    "    temperature=0.7,  \n",
    "    repetition_penalty=1.2, \n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "print(f\"Length of input_ids: {len(input_ids[0])}\")\n",
    "\n",
    "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(decoded_output)\n",
    "\n",
    "\n",
    "input_ids = tokenizer.encode(input_str, return_tensors='pt').to(device)\n",
    "output = model.generate(input_ids, max_length=1024)\n",
    "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f5ec60-1875-4734-a505-74c6378eb9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba3a96-eea0-4db4-99d0-c99974162afd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
